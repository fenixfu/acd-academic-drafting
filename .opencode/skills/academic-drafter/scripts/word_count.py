# utf-8
#!/usr/bin/env python3
"""
å­—æ•°ç»Ÿè®¡ç¨‹åº - ç”¨äºæ ¸éªŒä¸­æ–‡å­¦æœ¯æ–‡æœ¬å­—æ•°

è®¡æ•°è§„åˆ™ï¼š
  - ä¸­æ–‡å­—ç¬¦ï¼ˆå«æ ‡ç‚¹ï¼‰: æ¯ä¸ªè®¡ 1 å­—
  - è‹±æ–‡å•è¯ï¼ˆè¿ç»­å­—æ¯/æ•°å­—åºåˆ—ï¼‰: æ¯ä¸ªè®¡ 2 å­—ï¼ˆç­‰æ•ˆæ¢ç®—ï¼‰
  - å…¶ä»–ç¬¦å·ï¼ˆæ‹¬å·ã€ç ´æŠ˜å·ç­‰éä¸Šè¿°å­—ç¬¦ï¼‰: æ¯ä¸ªè®¡ 1 å­—
  - ç©ºæ ¼ä¸è®¡å…¥

åˆ†åŒºé€»è¾‘ï¼š
  - æ­£æ–‡ï¼šä»ç¬¬ä¸€ä¸ªéå…ƒæ•°æ®è¡Œèµ·ï¼Œåˆ°å‚è€ƒæ–‡çŒ®èŠ‚å‰
  - å‚è€ƒæ–‡çŒ®ï¼šä»¥ "å‚è€ƒæ–‡çŒ®"ã€"References"ã€"Bibliography" æ ‡é¢˜è¡Œæˆ–
    è¿ç»­ç¼–å·åˆ—è¡¨ï¼ˆ"[1]" / "1."ï¼‰å¼€å¤´çš„åŒºæ®µ
  - åˆ†åˆ«ç»Ÿè®¡åç»™å‡ºåˆè®¡æ€»å’Œ
"""

import re
import sys
from pathlib import Path

# â”€â”€ è®¡æ•°é…ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ENGLISH_WORD_EQUIV = 2   # 1 è‹±æ–‡å•è¯ç­‰æ•ˆ N å­—
WORD_LIMIT = 800         # é»˜è®¤å­—æ•°ä¸Šé™ï¼ˆæ­£æ–‡ï¼‰


def strip_markdown(text: str) -> str:
    """ç§»é™¤ markdown æ ¼å¼æ ‡è®°ï¼Œä¿ç•™çº¯æ–‡æœ¬å†…å®¹ã€‚"""
    # æ ‡é¢˜æ ‡è®° (# ## ### ç­‰è¡Œé¦–äº•å·)
    text = re.sub(r"^#{1,6}\s*", "", text, flags=re.MULTILINE)
    # ç²—ä½“/æ–œä½“æ ‡è®° (** * __ _)
    text = re.sub(r"\*{1,3}|_{1,3}", "", text)
    # åˆ é™¤çº¿ ~~
    text = re.sub(r"~~", "", text)
    # è¡Œå†…ä»£ç  `
    text = re.sub(r"`", "", text)
    # å¼•ç”¨æ ‡è®° >
    text = re.sub(r"^>\s*", "", text, flags=re.MULTILINE)
    # æ— åºåˆ—è¡¨æ ‡è®° (- * + è¡Œé¦–)
    text = re.sub(r"^[\-\*\+]\s+", "", text, flags=re.MULTILINE)
    # é“¾æ¥ [text](url) â†’ text
    text = re.sub(r"\[([^\]]*)\]\([^)]*\)", r"\1", text)
    # å›¾ç‰‡ ![alt](url) â†’ ç§»é™¤
    text = re.sub(r"!\[([^\]]*)\]\([^)]*\)", "", text)
    # æ°´å¹³çº¿ --- ***
    text = re.sub(r"^[-*_]{3,}\s*$", "", text, flags=re.MULTILINE)
    return text


def count_text(text: str) -> dict:
    """
    ç»Ÿè®¡ä¸€æ®µæ–‡æœ¬çš„ç­‰æ•ˆå­—æ•°ã€‚
    è‡ªåŠ¨å‰¥ç¦» markdown æ ¼å¼æ ‡è®°åå†è®¡æ•°ã€‚

    Returns dict with keys:
        chinese_chars, english_words, english_equiv,
        other_symbols, total
    """
    text = strip_markdown(text)

    chinese_chars = len(re.findall(
        r"[\u4e00-\u9fff\u3000-\u303f\uff00-\uffef]", text
    ))
    english_words = len(re.findall(r"[a-zA-Z0-9]+", text))
    other_symbols = len(re.findall(
        r"[^\u4e00-\u9fff\u3000-\u303f\uff00-\uffef\sa-zA-Z0-9]", text
    ))

    english_equiv = english_words * ENGLISH_WORD_EQUIV
    total = chinese_chars + english_equiv + other_symbols

    return {
        "chinese_chars": chinese_chars,
        "english_words": english_words,
        "english_equiv": english_equiv,
        "other_symbols": other_symbols,
        "total": total,
    }


# â”€â”€ Markdown åˆ†åŒºæå– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_REF_HEADING_RE = re.compile(
    r"^#{1,6}\s*(å‚è€ƒæ–‡çŒ®|References|Bibliography)\s*$",
    re.IGNORECASE,
)
_REF_INLINE_RE = re.compile(
    r"^[\*\[\ã€\(\ï¼ˆ\{\<]*?(å‚è€ƒæ–‡çŒ®|References|Bibliography)\S*?\s*$",
    re.IGNORECASE,
)
# è¿ç»­ç¼–å·åˆ—è¡¨é¦–è¡Œï¼š[1] æˆ– 1.
_REF_NUMBERED_RE = re.compile(r"^\[1\]|^1\.\s")

# å…ƒæ•°æ®è¡Œï¼ˆæ ‡é¢˜è¡Œã€blockquoteã€yaml fence ç­‰ï¼Œæ’é™¤æ­£æ–‡èµ·å§‹ç‚¹ä¹‹åçš„æ ‡é¢˜ï¼‰
_META_RE = re.compile(r"^(#|>|---|```|<!--)")


def split_sections(content: str):
    """
    å°† markdown å†…å®¹æ‹†åˆ†ä¸º (æ­£æ–‡æ–‡æœ¬, å‚è€ƒæ–‡çŒ®æ–‡æœ¬)ã€‚

    é€»è¾‘ï¼š
    1. è·³è¿‡æ–‡ä»¶å¼€å¤´çš„å…ƒæ•°æ®è¡Œï¼ˆ#ã€>ã€--- ç­‰ï¼‰
    2. é‡åˆ°å‚è€ƒæ–‡çŒ®èŠ‚æ ‡è¯†æ—¶åˆ‡æ¢åˆ°å‚è€ƒæ–‡çŒ®åŒº
    3. è¿”å›ä¸¤æ®µçº¯æ–‡æœ¬
    """
    lines = content.splitlines()

    body_lines = []
    ref_lines = []
    in_ref = False
    body_started = False

    for line in lines:
        stripped = line.strip()

        # æ£€æµ‹å‚è€ƒæ–‡çŒ®èŠ‚å¼€å§‹
        if not in_ref and (
            _REF_HEADING_RE.match(stripped)
            or _REF_INLINE_RE.match(stripped)
        ):
            in_ref = True
            ref_lines.append(line)
            continue

        if in_ref:
            ref_lines.append(line)
            continue

        # æ­£æ–‡å°šæœªå¼€å§‹æ—¶è·³è¿‡å…ƒæ•°æ®è¡Œ
        if not body_started:
            if stripped and not _META_RE.match(stripped):
                body_started = True
            else:
                continue  # è·³è¿‡å…ƒæ•°æ®

        # æ­£æ–‡ä¸­å‡ºç°ç¼–å·åˆ—è¡¨é¦–è¡Œï¼Œä¸”å·²æœ‰è¶³å¤Ÿæ­£æ–‡ï¼Œè§†ä¸ºå‚è€ƒæ–‡çŒ®å¼€å§‹
        if body_started and _REF_NUMBERED_RE.match(stripped):
            # åªæœ‰åœ¨æ­£æ–‡å·²æœ‰å†…å®¹æ—¶æ‰åˆ‡æ¢ï¼ˆé¿å…è¯¯åˆ¤æ­£æ–‡å†…ç¼–å·ï¼‰
            if len(body_lines) > 5:
                in_ref = True
                ref_lines.append(line)
                continue

        body_lines.append(line)

    return "\n".join(body_lines), "\n".join(ref_lines)


# â”€â”€ æ˜¾ç¤ºè¾…åŠ© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fmt_stats(stats: dict, label: str, limit: int | None = None) -> None:
    print(f"\n  ã€{label}ã€‘")
    print(f"    ä¸­æ–‡å­—ç¬¦  : {stats['chinese_chars']} å­—")
    print(f"    è‹±æ–‡å•è¯  : {stats['english_words']} è¯ Ã— {ENGLISH_WORD_EQUIV} = {stats['english_equiv']} å­—ï¼ˆç­‰æ•ˆï¼‰")
    print(f"    å…¶ä»–ç¬¦å·  : {stats['other_symbols']} ä¸ª")
    print( "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"    å°è®¡      : {stats['total']} å­—")
    if limit is not None:
        remaining = limit - stats["total"]
        if remaining >= 0:
            print(f"    âœ… ç¬¦åˆä¸Šé™ {limit} å­—ï¼Œå‰©ä½™ {remaining} å­—")
        else:
            print(f"    âŒ è¶…å‡ºä¸Šé™ {limit} å­—ï¼Œè¶…å‡º {-remaining} å­—")


def check_file(filepath: str, limit: int = WORD_LIMIT) -> int:
    """æ£€æŸ¥æ–‡ä»¶ï¼Œåˆ†åˆ«ç»Ÿè®¡æ­£æ–‡ä¸å‚è€ƒæ–‡çŒ®ï¼Œè¿”å›åˆè®¡å­—æ•°ã€‚"""
    path = Path(filepath)
    if not path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        return 0

    content = path.read_text(encoding="utf-8")
    body_text, ref_text = split_sections(content)

    body_stats = count_text(body_text)
    ref_stats = count_text(ref_text)
    combined_total = body_stats["total"] + ref_stats["total"]

    print(f"\n{'=' * 60}")
    print(f"ğŸ“„ æ–‡ä»¶: {filepath}")
    print(f"{'=' * 60}")

    fmt_stats(body_stats, "æ­£æ–‡ï¼ˆä¸å«å‚è€ƒæ–‡çŒ®ï¼‰", limit=limit)
    fmt_stats(ref_stats,  "å‚è€ƒæ–‡çŒ®")

    print(f"\n  åˆè®¡ï¼ˆæ­£æ–‡ + å‚è€ƒæ–‡çŒ®ï¼‰: {combined_total} å­—")
    print(f"{'=' * 60}")

    return combined_total


# â”€â”€ å…¥å£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    print("ğŸ“ å­¦æœ¯æ–‡æœ¬å­—æ•°ç»Ÿè®¡å·¥å…·")
    print("=" * 60)
    print(f"è®¡æ•°è§„åˆ™ï¼šè‹±æ–‡å•è¯ Ã— {ENGLISH_WORD_EQUIV}ï¼Œä¸­æ–‡å­—ç¬¦ Ã— 1ï¼Œç¬¦å· Ã— 1")
    print(f"é»˜è®¤æ­£æ–‡ä¸Šé™ï¼š{WORD_LIMIT} å­—")
    print("=" * 60)

    if len(sys.argv) > 1:
        # [ä¿®å¤] æ”¹ç”¨ range ç´¢å¼•éå†ï¼Œé¿å…é™æ€ç±»å‹æ£€æŸ¥å™¨å¯¹ list åˆ‡ç‰‡(sys.argv[1:])æŠ¥é”™
        for i in range(1, len(sys.argv)):
            check_file(sys.argv[i])
    else:
        # é»˜è®¤æŸ¥æ‰¾è¾“å‡ºç›®å½•ä¸‹çš„æ‘˜è¦æ–‡ä»¶
        # æ³¨æ„ï¼šè¿™é‡Œå‡è®¾è„šæœ¬ä½äºé¡¹ç›®æ·±å±‚ç›®å½•ï¼Œå¦‚æœå±‚çº§ä¸è¶³ parents[4] å¯èƒ½ä¼šè¶Šç•Œ
        try:
            project_root = Path(__file__).resolve().parents[4]  # 4 çº§å‘ä¸Šåˆ°é¡¹ç›®æ ¹
            candidates = list(project_root.glob("output/*.md"))
            
            if not candidates:
                print("\nâš ï¸ æœªæ‰¾åˆ°æ–‡ä»¶ï¼Œè¯·æŒ‡å®šè·¯å¾„:")
                print("  python word_count.py <æ–‡ä»¶è·¯å¾„>")
                return
            
            # å–æœ€æ–°ä¿®æ”¹çš„æ–‡ä»¶
            target = max(candidates, key=lambda p: p.stat().st_mtime)
            print(f"\nè‡ªåŠ¨é€‰å–æœ€æ–°æ–‡ä»¶: {target}")
            check_file(str(target))
        except IndexError:
            print("\nâš ï¸ æ— æ³•è‡ªåŠ¨å®šä½é¡¹ç›®æ ¹ç›®å½• (parents[4] è¶Šç•Œ)ã€‚")
            print("è¯·ç›´æ¥æä¾›æ–‡ä»¶è·¯å¾„: python word_count.py <æ–‡ä»¶è·¯å¾„>")


if __name__ == "__main__":
    main()
